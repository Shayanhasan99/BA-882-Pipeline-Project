{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_IevLaXUElS"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "!pip install pandas\n",
        "!pip install google-cloud-storage\n",
        "!pip install functions-framework==3.*\n",
        "!pip install google-cloud-secret-manager\n",
        "!pip install duckdb==1.1.0\n",
        "!pip isntall gcsfs\n",
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stock Overview**"
      ],
      "metadata": {
        "id": "2GmvaPbunsah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import functions_framework\n",
        "from google.cloud import secretmanager\n",
        "from google.cloud import storage\n",
        "import json\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# setup\n",
        "project_id = 'ba882-435919'\n",
        "secret_id = 'motherduck_access_token'\n",
        "version_id = '1'\n",
        "\n",
        "# db setup\n",
        "db = 'stocks'\n",
        "staging_db_schema = f\"{db}.stage\"\n",
        "reporting_db_schema = f\"{db}.report\"\n",
        "created_tables = {}\n",
        "\n",
        "############################################################### main task\n",
        "\n",
        "# Parse the request data\n",
        "\n",
        "# instantiate the services\n",
        "sm = secretmanager.SecretManagerServiceClient()\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Build the resource name of the secret version\n",
        "name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
        "\n",
        "# Access the secret version\n",
        "response = sm.access_secret_version(request={\"name\": name})\n",
        "md_token = response.payload.data.decode(\"UTF-8\")\n",
        "\n",
        "# initiate the MotherDuck connection through an access token through\n",
        "md = duckdb.connect(f'md:?motherduck_token={md_token}')\n",
        "\n",
        "# create stage schema if first time running function\n",
        "create_schema = f\"CREATE SCHEMA IF NOT EXISTS {reporting_db_schema};\"\n",
        "md.sql(create_schema)\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ tbl: news\n",
        "tbl_name = 'news_story_unique'\n",
        "# read in from md\n",
        "fetch_news = f\"SELECT * FROM {staging_db_schema}.news;\"\n",
        "df = md.sql(fetch_news).df()\n",
        "\n",
        "# Adding cols\n",
        "df['scraped_text'] = 'Not Found'\n",
        "df['bullets'] = 'Not Found'\n",
        "df['summary'] = 'Not Found'\n",
        "\n",
        "unique_uuid = df.drop_duplicates(subset=['uuid']) # dropping articles that are repeated for multiple tickers\n",
        "unique_uuid = unique_uuid[unique_uuid['type']=='STORY'] # scraper code only works for articles, not VIDEOS\n",
        "\n",
        "try: # filter out existing scraped articles\n",
        "  fetch_existing_table = f\"SELECT * FROM {reporting_db_schema}.{tbl_name};\"\n",
        "  anti_df = md.sql(fetch_existing_table).df()\n",
        "  uuids = anti_df['uuid'].to_list()\n",
        "  unique_uuid.loc[~unique_uuid['uuid'].isin(uuids)]\n",
        "  # unique_uuid = anti_join\n",
        "except: pass\n",
        "\n",
        "# Scraping\n",
        "\n",
        "for i, row in enumerate(unique_uuid.values):\n",
        "  url = row[3]\n",
        "  print(url)\n",
        "\n",
        "  try:\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract the article content\n",
        "    article_body = soup.find('div', class_='body yf-5ef8bf')\n",
        "    paragraphs = article_body.find_all('p')\n",
        "    content = '\\n\\n'.join([p.text for p in paragraphs])\n",
        "    print(content)\n",
        "    unique_uuid.iloc[i,-3] = content\n",
        "  except Exception as error:\n",
        "    print(str(error) + ' Content is likely behind paywall')\n",
        "    unique_uuid.iloc[i,-3] = 'Paywall'\n",
        "\n",
        "# load from df\n",
        "reporting_sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {reporting_db_schema}.{tbl_name} AS SELECT * FROM unique_uuid;\"\"\"\n",
        "print(f\"{reporting_sql}\")\n",
        "md.sql(reporting_sql)\n",
        "# del parquet_df\n"
      ],
      "metadata": {
        "id": "KVbxphkJ6Nfz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}